{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "The code below is responsible of the first part of our strategy: pair selection. Change the 'start_time' and 'end_time' value in the function $\\textbf{def get_eq_data(symbol_)}$ to adjust the training period. The default resolution of our selection is set to be Daily to speed up computation. Ideally, one may want to modify it to be of Minute resolution to produce more accurate results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from itertools import combinations\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Idiot version\n",
    "symbols = [\"AAPL\",\"MSFT\",\"AMZN\",\"NVDA\",\"GOOGL\",\"BRK.B\",\"GOOG\",\"TSLA\",\"XOM\",\"UNH\",\"META\",\"JPM\",\"JNJ\",\"V\",\"PG\",\"MA\",\"HD\",\"CVX\",\"MRK\",\"ABBV\",\"AVGO\",\"LLY\",\"PEP\",\"KO\",\"BAC\",\"PFE\",\"TMO\",\"COST\",\"CSCO\",\"WMT\",\"MCD\",\"CRM\",\"DIS\",\"LIN\",\"ABT\",\"WFC\",\"ACN\",\"DHR\",\"ADBE\",\"TXN\",\"VZ\",\"CMCSA\",\"PM\",\"NKE\",\"NEE\",\"RTX\",\"BMY\",\"NFLX\",\"AMD\",\"ORCL\",\"QCOM\",\"UPS\",\"COP\",\"T\",\"HON\",\"CAT\",\"MS\",\"UNP\",\"LOW\",\"AMGN\",\"GS\",\"SBUX\",\"INTU\",\"DE\",\"BA\",\"SCHW\",\"IBM\",\"PLD\",\"SPGI\",\"LMT\",\"ELV\",\"INTC\",\"CVS\",\"AXP\",\"MDT\",\"AMAT\",\"BLK\",\"GILD\",\"BKNG\",\"C\",\"ADI\",\"GE\",\"ADP\",\"AMT\",\"TJX\",\"NOW\",\"SYK\",\"MDLZ\",\"PYPL\",\"TMUS\",\"CI\",\"CB\",\"PGR\",\"MO\",\"ISRG\",\"MMC\",\"REGN\",\"ZTS\",\"SLB\",\"TGT\",\"FISV\",\"VRTX\",\"DUK\",\"SO\",\"ETN\",\"EOG\",\"NOC\",\"LRCX\",\"BSX\",\"BDX\",\"ITW\",\"CME\",\"APD\",\"EQIX\",\"CSX\",\"AON\",\"HUM\",\"MU\",\"USB\",\"MPC\",\"CL\",\"MMM\",\"PNC\",\"TFC\",\"FCX\",\"EL\",\"ICE\",\"GM\",\"ATVI\",\"CCI\",\"WM\",\"SNPS\",\"KLAC\",\"CDNS\",\"HCA\",\"ORLY\",\"SHW\",\"VLO\",\"F\",\"GD\",\"EMR\",\"FDX\",\"NSC\",\"DG\",\"PXD\",\"MCK\",\"EW\",\"NXPI\",\"PSX\",\"PSA\",\"APH\",\"GIS\",\"MRNA\",\"AZO\",\"SRE\",\"MAR\",\"MCHP\",\"MCO\",\"PH\",\"AEP\",\"D\",\"NUE\",\"OXY\",\"MET\",\"ROP\",\"JCI\",\"CTVA\",\"MSI\",\"ADSK\",\"DXCM\",\"ADM\",\"MSCI\",\"AIG\",\"CMG\",\"TRV\",\"A\",\"KMB\",\"TEL\",\"EXC\",\"O\",\"FTNT\",\"DOW\",\"HLT\",\"COF\",\"IDXX\",\"CARR\",\"PCAR\",\"SPG\",\"LHX\",\"AJG\",\"MNST\",\"IQV\",\"TDG\",\"ECL\",\"CNC\",\"CHTR\",\"SYY\",\"BIIB\",\"ROST\",\"AFL\",\"CTAS\",\"HES\",\"FIS\",\"WMB\",\"BK\",\"ANET\",\"AMP\",\"PAYX\",\"CMI\",\"DD\",\"YUM\",\"ON\",\"OTIS\",\"STZ\",\"DVN\",\"WELL\",\"XEL\",\"PRU\",\"HSY\",\"ROK\",\"KMI\",\"HAL\",\"MTD\",\"URI\",\"NEM\",\"ALL\",\"ILMN\",\"ED\",\"VICI\",\"AME\",\"ODFL\",\"STT\",\"CTSH\",\"BKR\",\"APTV\",\"GWW\",\"RMD\",\"KR\",\"PPG\",\"CPRT\",\"KHC\",\"DLR\",\"GPN\",\"DFS\",\"FAST\",\"OKE\",\"DLTR\",\"ALB\",\"DHI\",\"EA\",\"PEG\",\"ENPH\",\"KDP\",\"VRSK\",\"CSGP\",\"KEYS\",\"WEC\",\"ULTA\",\"SBAC\",\"CDW\",\"CBRE\",\"IT\",\"PCG\",\"RSG\",\"WTW\",\"EIX\",\"ANSS\",\"ACGL\",\"GLW\",\"ES\",\"HPQ\",\"ZBH\",\"CEG\",\"TROW\",\"TSCO\",\"FANG\",\"LEN\",\"AWK\",\"DAL\",\"WBA\",\"ABC\",\"MTB\",\"EFX\",\"AVB\",\"EBAY\",\"ALGN\",\"GPC\",\"LYB\",\"VMC\",\"IR\",\"FTV\",\"HIG\",\"WST\",\"FITB\",\"PWR\",\"WY\",\"IFF\",\"MLM\",\"MPWR\",\"STLD\",\"DOV\",\"EXR\",\"AEE\",\"FE\",\"ARE\",\"FSLR\",\"ETR\",\"FRC\",\"EQR\",\"LH\",\"HBAN\",\"RJF\",\"DTE\",\"RF\",\"CHD\",\"LUV\",\"CTRA\",\"PPL\",\"TDY\",\"BAX\",\"HOLX\",\"HPE\",\"LVS\",\"PFG\",\"WAB\",\"NTRS\",\"CAH\",\"VTR\",\"MOS\",\"CFG\",\"NDAQ\",\"CINF\",\"WAT\",\"VRSN\",\"OMC\",\"CLX\",\"SWKS\",\"INVH\",\"MKC\",\"TTWO\",\"XYL\",\"EXPD\",\"STE\",\"SEDG\",\"DRI\",\"UAL\",\"MAA\",\"EPAM\",\"CNP\",\"BALL\",\"TRGP\",\"CMS\",\"TSN\",\"CAG\",\"BR\",\"IEX\",\"CF\",\"K\",\"AMCR\",\"NVR\",\"BBY\",\"COO\",\"AES\",\"TER\",\"MRO\",\"SJM\",\"HWM\",\"FMC\",\"EXPE\",\"KEY\",\"DGX\",\"ZBRA\",\"RCL\",\"FLT\",\"MOH\",\"J\",\"SYF\",\"ATO\",\"PKI\",\"SIVB\",\"IRM\",\"TXT\",\"JBHT\",\"FDS\",\"GRMN\",\"RE\",\"LKQ\",\"ESS\",\"MGM\",\"AVY\",\"NTAP\",\"LW\",\"ETSY\",\"POOL\",\"PAYC\",\"INCY\",\"TYL\",\"IPG\",\"MKTX\",\"IP\",\"EVRG\",\"WRB\",\"SNA\",\"BRO\",\"CBOE\",\"PKG\",\"UDR\",\"PTC\",\"LDOS\",\"LNT\",\"CHRW\",\"TRMB\",\"PHM\",\"VTRS\",\"APA\",\"PEAK\",\"CTLT\",\"STX\",\"SWK\",\"KIM\",\"CPT\",\"JKHY\",\"BWA\",\"WYNN\",\"NDSN\",\"AKAM\",\"WDC\",\"CE\",\"EQT\",\"HRL\",\"MAS\",\"TECH\",\"BF.B\",\"L\",\"KMX\",\"CZR\",\"NI\",\"DPZ\",\"CDAY\",\"CRL\",\"TPR\",\"HSIC\",\"CPB\",\"GL\",\"MTCH\",\"AAL\",\"FOXA\",\"GEN\",\"TFX\",\"QRVO\",\"EMN\",\"BIO\",\"CCL\",\"TAP\",\"ALLE\",\"JNPR\",\"LYV\",\"REG\",\"PNR\",\"BXP\",\"BBWI\",\"RHI\",\"CMA\",\"PNW\",\"FFIV\",\"AOS\",\"HII\",\"UHS\",\"XRAY\",\"ROL\",\"AAP\",\"WRK\",\"NRG\",\"IVZ\",\"BEN\",\"FRT\",\"VFC\",\"GNRC\",\"WHR\",\"SEE\",\"ZION\",\"HAS\",\"NWSA\",\"AIZ\",\"SBNY\",\"NCLH\",\"DXC\",\"ALK\",\"OGN\",\"MHK\",\"NWL\",\"RL\",\"FOX\",\"LNC\",\"DVA\",\"DISH\",\"LUMN\",\"NWS\"]\n",
    "\n",
    "# hundred_symbols = []\n",
    "# for i in range(5):\n",
    "#     hundred_symbols.append(symbols[i*100:min((i+1)*100,len(symbols))])\n",
    "# symbols = sorted(hundred_symbols[1])\n",
    "\n",
    "symbols = sorted(symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_eq_data(symbol_):\n",
    "    \n",
    "    qb = QuantBook()\n",
    "\n",
    "    symbol = qb.AddEquity(symbol_, Resolution.Hour).Symbol\n",
    "    # Change date manually\n",
    "    start_time = datetime(2023, 2, 1)\n",
    "    end_time = datetime(2023, 2, 28)\n",
    "\n",
    "    hist = qb.History(symbol, start_time, end_time, Resolution.Daily)\n",
    "\n",
    "    if not hist.empty:\n",
    "        data = pd.DataFrame()\n",
    "        data[symbol_] = hist['close'].to_list()\n",
    "        hist_index = hist.index.to_list()\n",
    "        list_ = []\n",
    "        for i in hist_index:\n",
    "            list_.append(i[1])\n",
    "        data.index = list_\n",
    "        return data\n",
    "\n",
    "    else:\n",
    "        print(symbol_ + \" not found\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def normalise(data):\n",
    "    return data/data.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_eq_norm_data(symbol_list):\n",
    "    hist_data = pd.DataFrame()\n",
    "    remove_symbols = []\n",
    "    for i in tqdm(range(len(symbol_list))):\n",
    "        symbol = symbol_list[i]\n",
    "        temp_data = get_eq_data(symbol)\n",
    "        if temp_data.empty:\n",
    "            remove_symbols.append(symbol)\n",
    "\n",
    "        else:\n",
    "            # print(\"Getting data of \" + symbol + \"...\")\n",
    "            # print(temp_data.index[0])\n",
    "            if hist_data.empty:\n",
    "                hist_data = get_eq_data(symbol)\n",
    "            else:\n",
    "                hist_data = pd.concat([hist_data,get_eq_data(symbol)], join = \"inner\", axis = 1)\n",
    "\n",
    "    for symbol in remove_symbols:\n",
    "        symbols.remove(symbol)\n",
    "        \n",
    "    return normalise(hist_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate DCCT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $X_1,X_2,...,X_T$ be a time series of price data, after normalising, we get $\\{x_1,x_2,...x_T\\} = \\{1,\\frac{X_2}{X_1},...,\\frac{X_T}{X_1}\\}$ and now we proceed to calculate CCT and DCCT\n",
    "<br/><br/>\n",
    "The formula of CCT is given by:\n",
    "<br/><br/>\n",
    "$CCT = \\frac{1}{n}\\sum_{l=1}^{n} max\\{CCT_k (m+1+p\\cdot(l-1)) | -m \\leq k \\leq m\\}$\n",
    "where\n",
    "<br/><br/>\n",
    "$CCT_k(i) = \\frac{\\sum_{j=i}^{i+p-1}(x_{j+1}-x_j)(y_{j+k+1}-y_{j+k})}{\\sqrt{\\sum_{j=i}^{i+p-1}(x_{j+1}-x_j)^2} \\sqrt{\\sum_{j=i}^{i+p-1}(y_{j+k+1}-y_{j+k})^2}}$\n",
    "<br/><br/>\n",
    "where p here is the predetermined window size; m is denotes the maximum value of lead or lag being taken into consideration for the calculation of dissimilarity (=100 by default)\n",
    "between the two-time series.\n",
    "<br/><br/>\n",
    "We would first constrcut the function for $CCT_k(i)$ as it is more straightforward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# warning: need to ensure that i+p <= len(x)\n",
    "def CCT_k(x,y,k,i,p): #calculate CCT_k (i)\n",
    "    \"\"\"\n",
    "    ======Input======\n",
    "    x: a list of normalized price data of stock X\n",
    "    y: a list of normalized price data of stock Y\n",
    "    k: lead lag \n",
    "    i: index of function\n",
    "    p: predetermined window size\n",
    "    ======Output======\n",
    "    return: CCT_k\n",
    "    \"\"\"\n",
    "    numerator = 0\n",
    "    denominator1 = 0\n",
    "    denominator2 = 0\n",
    "    for j in range(i-1,i+p-1):\n",
    "        numerator += (x[j+1] - x[j])*(y[j+k+1]-y[j+k])\n",
    "        denominator1 += (x[j+1] - x[j])**2\n",
    "        denominator2 += (y[j+k+1] - y[j+k])**2\n",
    "    denominator1 = math.sqrt(denominator1)\n",
    "    denominator2 = math.sqrt(denominator2)\n",
    "    \n",
    "    return numerator/(denominator1*denominator2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us make it clear what data from the time series are being used in the calculation of CCT:\n",
    "<br/><br/>\n",
    "First of all, from the formula of $CCT_k(i)$, it is easy to see that the data $\\{x_i,...,x_{i+p}\\}$ and $\\{y_{i+k},..,y_{i+p+k}\\}$ are required.\n",
    "<br/><br/>\n",
    "Substituting $i = m+1+p(l-1)$ (as in the formula of CCT), we see that we would need the data $\\{y_i\\}$,\n",
    "<br/><br/>\n",
    "with i ranging from $m+1+p(l-1)+k$ to $m+1+p(l-1)+p+k$\n",
    "<br/><br/>\n",
    "In addition, since we need to sum from $l=1$ to $l=n$, we would need i's starting from $m+1$ (take l=1 in $m+1+p(l-1)+k$) up till $1+np+m+k$ (taking l=n in m+1+p(l-1)+p+k).\n",
    "<br/><br/>\n",
    "Finally, as we also need k to go from $-m$ to $m$, we indeed need a the $\\{y_i\\}_{i\\in\\{1,2,...,1+np+2m\\}}$ (and $\\{x_i\\}_{i \\in \\{m+1,m+2,...,1+np+m\\}}$, by similar argument)\n",
    "<br/><br/>\n",
    "Therefore, we want to take m (maximum lead-lag value),n (number of segments that we want to divide [m+1,T-m-1] into) and p ($ = \\frac{length([m+1,T-m-1])}{n}$) in the way such that $2m+np+1 = T$. Bearing in mind these requirements, we proceed construct the function used to calculate $CCT$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CCT_all(x,y,n,p,m=5): #note that by definition we need n to be a divisor of T-m-1-(m+1) = T-2(m-1)\n",
    "    \"\"\"\n",
    "    ======Input======\n",
    "    x: a list of normalized price data of stock X\n",
    "    y: a list of normalized price data of stock Y\n",
    "    n: number of segments \n",
    "    p: predetermined window size\n",
    "    m: max value of lead or lag (default by 5)\n",
    "    ======Output======\n",
    "    return: max CCT_k \n",
    "    \"\"\"\n",
    "    for l in range(1,n+1):\n",
    "        CCT = 0\n",
    "        \n",
    "        #calculate max{CCT_k (m+1+p(l-1)) | -m <= k <= m}\n",
    "        max_CCT_k = CCT_k(x , y , -m, m+1+p*(l-1) ,p)\n",
    "        for k in range(-m+1,m+1):\n",
    "            current_CCT = CCT_k(x , y , k, m+1+p*(l-1) ,p)\n",
    "            if  current_CCT > max_CCT_k:\n",
    "                max_CCT_k = current_CCT\n",
    "        \n",
    "        CCT += max_CCT_k\n",
    "        \n",
    "    CCT /= n\n",
    "    \n",
    "    return CCT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we compute the $DCCT$ (i.e. Dynamic-cross-correlation-type) measure between two (normalised) time series. Intuitively speaking, two time series may look \"alike\" in a sense that is much broader than curve translation and scaling. The technique of dynamic time warpping allows us to compute the \"alignment path\" between two time series.\n",
    "\n",
    "The [figure](https://drive.google.com/file/d/1UUIGUlWdzbBiTl9E46Q8UTLQEzOiTzjL/view?usp=share_link) coming from the paper can be used to illustrate the idea:\n",
    "<br/><br/>\n",
    "Denote the data from the blue (upper) time series by $\\{x_t\\}_{t \\in \\{1,2,...,30\\}}$ and the lower one by $\\{y_t\\}_{t \\in \\{1,2,...,30\\}}$. We see that the two curves are similar, and the similarity can be captured when we identify $x_1$ with $y_1,y_2,y_3$, identify $x_2$ with $y_4$ etc. This identification is encoded by an alignment path $P = (P_1,P_2,...,P_L)$, with $P_k = (p_k,q_k) \\in \\{1,2,...,n\\}^2$.\n",
    "<br/><br/>\n",
    "In this case, we have $(p_1,q_1) = (1,1)$ (meaning that $x_1$ is identified with $y_1$), $(p_2,q_2) = (1,2)$ (meaning that $x_1$ is identified with $y_2$); similarly $(p_3,q_3)=(1,3), (p_4,q_4) = (2,4)$ etc.\n",
    "<br/><br/>\n",
    "\n",
    "We require the alignment path to satisfy the following conditions:\n",
    "<br/><br/>\n",
    "1. Boundary condition: given a parameter psi (which stands for Post Suffix Invariant, default = 100), we need $p_1q_1 \\leq psi; p_L, q_L \\geq n - psi + 1$\n",
    "2. Monotonicity condition: $p_1\\leq p_2 \\leq ... \\leq p_n, q_1\\leq q_2 \\leq... \\leq q_n$\n",
    "3. Step size condition: $P_{l+1}-P_l \\in \\{(1,0),(0,1),(1,1)\\}$\n",
    "<br/><br/>\n",
    "Remark: condition 2 is redundant since it is obvious implied by condition 3, but we keep it here as in the practice of the paper \n",
    "<br/><br/>\n",
    "\n",
    "Now, given a pair of stock with normalised time series on price data $\\{x_1,...,x_n\\}$ and $\\{y_1,...,y_n\\}$ we would construct an algorithm to compute the $DCCT$, with the following steps:\n",
    "<br/><br/>\n",
    "Step 1: Given an alignment path $P = \\{(p_1,q_1),(p_2,q_2),...,(p_L,q_L)\\}$, and for each $i \\in \\{1,2,...,L-p\\}$, compute the function\n",
    "$CR(p_i,q_i) = \\frac{\\sum_{j=i}^{i+p-1}(x_{p_{j+1}}-x_{p_j})(y_{q_{j+1}}-y_{q_j})}{\\sqrt{\\sum_{j=i}^{i+p-1}(x_{p_{j+1}}-x_{p_j})^2} \\sqrt{\\sum_{j=i}^{i+p-1}(y_{q_{j+1}}-y_{q_j})^2}}$\n",
    "<br/><br/>\n",
    "(note: in the paper it said we would compute it for $i \\in \\{1,2,...,L\\}$, which is a mistake since computing $CR(p_i,q_i)$ requires the data $\\{(p_i,q_i),...,(p_{i+p},q_{i+p})\\}$, so clearly we can only do so for $i \\leq L-p$)\n",
    "<br/><br/>\n",
    "Step 2: Find an optimal path which minimises the function $\\sum_{i=1}^{L}CR(p_i,q_i)$\n",
    "<br/><br/>\n",
    "Step 3: The DCCT measure is then obatined by\n",
    "<br/><br/>\n",
    "$DCCT = \\max_{all paths}\\sum_{i=1}^{L}CR(p_i,q_i)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute CR(p_i,q_i) given the index i, alignment path P = [[p_1,q_1],...,[p_L,q_L]],\n",
    "# window size p and normalised prices x = [x_1,...x_n] y =[y_1,...,y_n]\n",
    "\n",
    "# Step 1\n",
    "def CR(x,y,p_i,q_i,p):\n",
    "    \"\"\"\n",
    "    ======Input======\n",
    "    x: a list of normalized price data of stock X\n",
    "    y: a list of normalized price data of stock Y\n",
    "    P: alignment path\n",
    "    i: index of series\n",
    "    p: predetermined window size\n",
    "    ======Output======\n",
    "    return: CR (a function over the sequence P_1)\n",
    "    \"\"\"\n",
    "    numerator = 0\n",
    "    denominator1 = 0\n",
    "    denominator2 = 0\n",
    "    \n",
    "    x_temp = [0]*p + x + [0]*p\n",
    "    y_temp = [0]*p + y + [0]*p\n",
    "    \n",
    "    for j in range(p + -p, p + p+1):\n",
    "        #similarly we need to -1 from the index since for example, the index of x_1 is 0 (i.e. x_1 is x[0]), so x_{p_j +1} is x[P[j][0]] etc.\n",
    "        numerator += (x_temp[p_i + 1 + j -1] - x_temp[p_i + j -1])*(y_temp[q_i + 1 + j -1]-y_temp[q_i + j -1])\n",
    "        denominator1 += (x_temp[p_i + 1 + j -1] - x_temp[p_i + j -1])**2\n",
    "        denominator2 += (y_temp[q_i + 1 + j -1] - y_temp[q_i + j -1])**2\n",
    "\n",
    "    denominator1 = math.sqrt(denominator1)\n",
    "    denominator2 = math.sqrt(denominator2)\n",
    "    \n",
    "    return 2*(1-numerator/(denominator1*denominator2))\n",
    "\n",
    "# Step 2\n",
    "def sum_CR(x, y, P, p):\n",
    "    cr_total = 0\n",
    "    L = len(P)\n",
    "    for i in range(0, L):\n",
    "        cr_total += CR(x,y,P[i][0],P[i][1],p)\n",
    "    return cr_total\n",
    "\n",
    "\n",
    "def optimal_path_dtw(x, y, psi, m, p):\n",
    "    n, m = len(x), len(y)\n",
    "    d = np.zeros((n, m))\n",
    "    d[:, :] = np.inf\n",
    "    d[0, 0] = 0\n",
    "\n",
    "    for i in range(1, n):\n",
    "        j_min = max(1, i-psi)\n",
    "        j_max = min(m, i+psi)\n",
    "        for j in range(j_min, j_max):\n",
    "            if abs(i-j) <= m:\n",
    "                cost = CR(x, y, i-1, j-1, p)\n",
    "                d[i, j] = cost + min(d[i-1, j], d[i, j-1], d[i-1, j-1])\n",
    "\n",
    "    path = []\n",
    "    i, j = n-1, m-1\n",
    "    while (i, j) != (0, 0):\n",
    "        path.append((i, j))\n",
    "        candidates = []\n",
    "        if i > 0 and j > 0:\n",
    "            candidates.append((d[i-1, j-1], i-1, j-1))\n",
    "        if i > 0:\n",
    "            candidates.append((d[i-1, j], i-1, j))\n",
    "        if j > 0:\n",
    "            candidates.append((d[i, j-1], i, j-1))\n",
    "        cost, i, j = min(candidates)\n",
    "    path.append((0, 0))\n",
    "    path.reverse()\n",
    "    return np.array(path)\n",
    "\n",
    "def DCCT(x,y, p = 25,psi = 100,m = 100): # p can also be 25, 51, 101 as suggested by the paper\n",
    "    return sum_CR(x, y, optimal_path_dtw(x, y, psi, m, p), p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SSD(x,y):\n",
    "    n = len(x)\n",
    "    return np.sum( (np.array(x)-np.array(y))**2 )/n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_data = get_all_eq_norm_data(symbols)\n",
    "# 13 min for 1 month 500 stocks data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_dcct = {}\n",
    "pair_ssd = {}\n",
    "\n",
    "for pair in combinations(symbols,2):\n",
    "    pair_name = pair[0] +\":\"+ pair[1]\n",
    "    pair_dcct[pair_name] = DCCT(norm_data[pair[0]].to_list(), norm_data[pair[1]].to_list())\n",
    "    pair_ssd[pair_name] = SSD(norm_data[pair[0]].to_list(), norm_data[pair[1]].to_list())\n",
    "\n",
    "# 25 min for 1 month data\n",
    "# 100 min for 2 month data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_pair_dcct = dict(sorted(pair_dcct.items(), key=lambda item: item[1]))\n",
    "sorted_pair_ssd = dict(sorted(pair_ssd.items(), key=lambda item: item[1]))\n",
    "\n",
    "pair_rank = {}\n",
    "for pair in combinations(symbols,2):\n",
    "    pair_name =  pair[0] +\":\"+ pair[1]\n",
    "    pair_rank[pair_name] = int(list(sorted_pair_dcct).index(pair_name)) + int(list(sorted_pair_ssd).index(pair_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_rank = list(dict(sorted(pair_rank.items(), key=lambda item: item[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pairs(final_rank):\n",
    "    pairs = \"[\"\n",
    "    for pair in final_rank:\n",
    "        pairs += \"[\\\"\"\n",
    "        pairs += pair.replace(\":\",\"\\\",\\\"\")\n",
    "        pairs += \"\\\"],\"\n",
    "    pairs = pairs[:-1] + \"]\"\n",
    "    return pairs\n",
    "\n",
    "get_pairs(final_rank[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Eliminate dulplicate pairs. For example, if we have [[a,b],[b,c],[d,e],...] the pair [b,c] is removed since b is already used in\n",
    "the first pair\n",
    "'''\n",
    "\n",
    "def eliminate_duplicate(pairs):\n",
    "    clean_pairs = []\n",
    "    \n",
    "    for pair in pairs:\n",
    "        same_company = (pair == [\"GOOG\",\"GOOGL\"]) or (pair == [\"NWS\",\"NWSA\"]) or (pair == [\"FOX\",\"FOXA\"])\n",
    "        collision = False\n",
    "        for i in range(len(clean_pairs)):\n",
    "            collision = collision or ( (pair[0] == clean_pairs[i][0]) or (pair[0] == clean_pairs[i][1]) or (pair[1] == clean_pairs[i][0]) or (pair[1] == clean_pairs[i][1]) )\n",
    "        if(not (collision or same_company)) :\n",
    "            clean_pairs.append(pair)\n",
    "        else:\n",
    "            continue\n",
    "    return clean_pairs\n",
    "pairs = get_pairs(final_rank[:30])\n",
    "print(eliminate_duplicate(json.loads(pairs)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
